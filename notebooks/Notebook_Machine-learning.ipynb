{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Tuple\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split, StratifiedKFold\n",
    "\n",
    "# visualization tools:\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# models:\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
    "\n",
    "# evaluation functions:\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook goal: Setup a basic machine learning framework that cleans data, standardizes features,\n",
    "#  evaluates feature impt, shap values, and a myriad of ML algorithms\n",
    "# TODO: add the day-of-week as a feature\n",
    "# TODO: Add in target date versus historic reference dates\n",
    "# TODO: Add in volume-based feature functionality\n",
    "# TODO: Evaluate standardizing features per stock or one model per stock - may not be enough data realistically\n",
    "# TODO: Check bol-range-pct calculation - only giving zero value\n",
    "# TODO: Add profit point forecast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions:\n",
    "\n",
    "def clean_stock_data(dataframe: pd.DataFrame) -> pd.DataFrame :\n",
    "\n",
    "    '''removes nulls and in the future will be built out to do any additonal cleaning on the dataframe that is necessary\n",
    "    Args:\n",
    "        dataframe: pandas dataframe containing all of the potential features\n",
    "        parameters: \n",
    "            calculation_field: field on which all of the features are built\n",
    "\n",
    "    Returns:\n",
    "        dataframe: dataset that is ready to load into a machine learning framework\n",
    "    '''\n",
    "\n",
    "    #TODO: In pipeline write this output to the catalogue\n",
    "    # remove records the preceed the target period to have complete information:\n",
    "    dataframe = dataframe.dropna() \n",
    "    #dataframe = dataframe.reset_index(drop = True) # we won't reset the index for now for traceability back to the date, ticker combination later after training\n",
    "\n",
    "    # set the date as an index to us post-forecasting: This is a bad idea, come back to the concept\n",
    "    #dataframe.set_index(keys = 'date', verify_integrity = False, inplace = True) # verify integrity Fale to allow duplicates**\n",
    "    \n",
    "    # remove fields that will not be used as predictive features (can be hardcoded since dataframe structure will be the same):\n",
    "    dataframe = dataframe.drop(columns = [ 'date', 'high', 'low', 'open', 'volume', 'adj_close'])\n",
    "    \n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def identify_fields_to_standardize(dataframe: pd.DataFrame, parameters: Dict) -> np.array :\n",
    "\n",
    "    '''creates a list of the continuous fields to standardize by dimension within the predictive model; NOTE: this is used within the standardizer\n",
    "    \n",
    "    Args:\n",
    "        dataframe: dataframe that contains all of the fields of interest to be used in the calculations\n",
    "        parameters:\n",
    "            continuous_feature_cutoff: ratio of unique values to record count to be used to codify continuous features -> removes records from the standardization process which don't have enough data to standardize (e.g., boolean)\n",
    "\n",
    "    Returns: list of continuous fields to use in the standardization process based on user's specifications of \"uniqueness\" threshold    \n",
    "\n",
    "    '''\n",
    "\n",
    "    numeric_fields = dataframe.select_dtypes(include = 'number').columns\n",
    "    records = len(dataframe)\n",
    "\n",
    "    record_summary = pd.DataFrame(dataframe[numeric_fields].nunique(), columns = ['unique_values'])\n",
    "    record_summary['rows_in_df'] = records\n",
    "    record_summary['value_to_record_ratio'] = record_summary['unique_values']/ record_summary['rows_in_df']\n",
    "\n",
    "    # filter for a threshold specified by the user:\n",
    "    record_summary = record_summary[record_summary['value_to_record_ratio'] > parameters['continuous_feature_cutoff']]\n",
    "\n",
    "    # remove percentage features # TODO: later add in functionality to remove percentage based features\n",
    "\n",
    "    return record_summary.index\n",
    "\n",
    "\n",
    "# Justification for approach on scaling - the argument can be made that since our approach will generalize movemements across multiple securities that we need to standardize each security to its own price range.  Therefore, any features with price-relative values will be scaled per the security's price values to avoid odd splits in tree-based algos\n",
    "# the concern with standardization is generally focused on not letting any one feature have considerably more weight in a model than another; however in this case, \n",
    "\n",
    "\n",
    "def standardize_continuous_features(dataframe: pd.DataFrame, parameters: Dict) -> pd.DataFrame:\n",
    "\n",
    "    '''function that identifies the continuious features in the dataframe and standardizes each feature by equity to enable scaling relative to each equity\n",
    "    \n",
    "    Args:\n",
    "        Dataframe: Pandas dataframe to be used in machine learning\n",
    "        Parameters:\n",
    "            stock_field: field indicating the stock for the window function to scan\n",
    "            calculation_field: field for which the target is being calculated (used for drop in main row merge)\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe: containing the standardized data fields\n",
    "    \n",
    "    '''\n",
    "\n",
    "    continuous_fields = list(identify_fields_to_standardize(dataframe = dataframe, parameters = parameters))\n",
    "\n",
    "    # add in the ticker for grouping next:\n",
    "    continuous_fields.append(parameters['stock_field'])\n",
    "\n",
    "    # downselect to the fields that will be used to standardize:\n",
    "    continuous_dataframe = dataframe[continuous_fields]\n",
    "\n",
    "    # calculate z-scores: --> Standardizes within each feature to scale accordingly\n",
    "    z_scores = (continuous_dataframe - continuous_dataframe.groupby(by = parameters['stock_field']).transform('mean')) / continuous_dataframe.groupby(by = parameters['stock_field']).transform('std')\n",
    "\n",
    "    # drop the null ticker (not needed post groupby): \n",
    "    z_scores.drop(columns = [ parameters['stock_field'], parameters['calculation_field'] ], inplace = True)\n",
    "\n",
    "    # rename the fields to indicate standardization:\n",
    "    z_scores.columns = z_scores.columns + '_std'\n",
    "\n",
    "    # drop original continuous fields # TODO: coming back after calculation checks:\n",
    "    if parameters['drop_original_fields'] == True:\n",
    "        continuous_fields.remove(parameters['stock_field'])\n",
    "        dataframe.drop(columns = continuous_fields, inplace = True)\n",
    "\n",
    "    # append the fields back into the core dataframe:\n",
    "    z_scores = pd.concat([dataframe, z_scores], axis = 1)\n",
    "\n",
    "    # remove the standardized target field:\n",
    "    z_scores.drop(columns = z_scores.columns[z_scores.columns.str.contains('target')][1], inplace = True)\n",
    "\n",
    "    # remove unnecessary items:\n",
    "    del continuous_fields, continuous_dataframe\n",
    "\n",
    "    return z_scores\n",
    "\n",
    "\n",
    "\n",
    "def one_hot_encode_tickers(dataframe: pd.DataFrame, parameters: Dict) -> pd.DataFrame:\n",
    "\n",
    "    '''Returns one-hot encoded features to the predictive dataset NOTE: May not work, but this retains some of the information in the original dataframe while also potentially giving the global model a nudge\n",
    "       Note: we choose not to drop first for now, even though it's a trap; Can be used post processing or as model features\n",
    "    Args:\n",
    "        dataframe: core dataset that has been augmented with additional features\n",
    "        parameters:\n",
    "            stock_field: text field containing the \n",
    "    Returns:   \n",
    "        dataframe with augmented columns\n",
    "    \n",
    "    '''\n",
    "\n",
    "    dataframe = pd.get_dummies(data = dataframe, prefix = \"ind\", columns = [parameters['stock_field']], drop_first = False)\n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def profile_target_variable(dataframe: pd.DataFrame, parameters: dict):\n",
    "\n",
    "\n",
    "    '''Function that looks at the target variable and creates an output for the user to review and decide whether rebalancing will help classification task\n",
    "    Args:\n",
    "        dataframe: Main resulting dataframe from all data conversion steps\n",
    "        parameters:\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    # isolate the target variable:\n",
    "    target_field = list(dataframe.columns[dataframe.columns.str.contains('target')])\n",
    "\n",
    "    # create simple value count outputs:\n",
    "    target_summary_table = pd.DataFrame(dataframe[target_field].value_counts()).reset_index()\n",
    "    target_summary_table.rename(columns = {0 : 'counts'}, inplace = True)\n",
    "    target_summary_table['proportion'] = target_summary_table['counts'] / target_summary_table['counts'].sum()\n",
    "\n",
    "    # create bargraph and save it:\n",
    "    ''' TODO : resolve ability to output a matplotlib plot in kedro catalog\n",
    "    sns.countplot(x=target_field, data=dataframe)\n",
    "    plt.title(\"Class Distribution\")\n",
    "    plt.show() '''\n",
    "    target_field =', '.join(test.columns[test.columns.str.contains('target')].str.replace(r'\\[|\\]', ''))\n",
    "    positive_proportion = target_summary_table[target_summary_table[target_field].astype(int) == 1]['proportion'].to_list()\n",
    "   \n",
    "\n",
    "    print('Classification target: ' + str(target_field) + \" contains a class balance of: \" + str(positive_proportion) + \" in the positive case\")\n",
    "           \n",
    "\n",
    "    return target_summary_table # TODO: Write this to the catalogue as a reporting output for the users\n",
    "\n",
    "\n",
    "\n",
    "def create_training_test_splits(dataframe: pd.DataFrame, parameters: Dict) :\n",
    "\n",
    "    '''Function that splits out training and test sets for machine learning; for the purposes of this model the way we piose the problem allows for random train test split\n",
    "    Args:\n",
    "        dataframe: pandas dataframe containing only the target field and the features to be used by the classifier\n",
    "        parameters:\n",
    "            test_ratio: proportion of samples in the dataframe to be used as a test set once the models are tuned and evaluated\n",
    "\n",
    "    '''\n",
    "\n",
    "    # define Y and x:\n",
    "    target_feature = list(dataframe.columns[dataframe.columns.str.contains('target')])\n",
    "\n",
    "    y = dataframe[target_feature]\n",
    "    X = dataframe.drop(columns = target_feature)\n",
    "\n",
    "    # create the training and test splits:\n",
    "    X_train, X_test, y_train, y_test = train_test_split( X, y, test_size=parameters['test_size'], random_state=parameters['seed'], stratify = y)\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[12/30/23 16:43:50] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'combined_modeling_input'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <a href=\"file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py#344\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[12/30/23 16:43:50]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'combined_modeling_input'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m        \u001b]8;id=183815;file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=368792;file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py#344\u001b\\\u001b[2m344\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = catalog.load('combined_modeling_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: clean stock data:\n",
    "\n",
    "df = clean_stock_data(dataframe = df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>close</th>\n",
       "      <th>ticker</th>\n",
       "      <th>7_close_sma</th>\n",
       "      <th>14_close_sma</th>\n",
       "      <th>21_close_sma</th>\n",
       "      <th>7_close_std</th>\n",
       "      <th>14_close_std</th>\n",
       "      <th>21_close_std</th>\n",
       "      <th>above_7_close_sma_ind</th>\n",
       "      <th>7_close_sma_pct_diff</th>\n",
       "      <th>above_14_close_sma_ind</th>\n",
       "      <th>14_close_sma_pct_diff</th>\n",
       "      <th>above_21_close_sma_ind</th>\n",
       "      <th>21_close_sma_pct_diff</th>\n",
       "      <th>cum_days_above_above_7_close_sma_ind</th>\n",
       "      <th>cum_days_above_above_14_close_sma_ind</th>\n",
       "      <th>cum_days_above_above_21_close_sma_ind</th>\n",
       "      <th>upper_bollinger_band</th>\n",
       "      <th>lower_bollinger_band</th>\n",
       "      <th>bol_pct_from_top</th>\n",
       "      <th>bol_pct_from_bottom</th>\n",
       "      <th>bol_range</th>\n",
       "      <th>bol_range_pct</th>\n",
       "      <th>target_20_days_ahead</th>\n",
       "      <th>target_20_days_ahead_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>41.610001</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>39.537500</td>\n",
       "      <td>38.988036</td>\n",
       "      <td>38.541548</td>\n",
       "      <td>1.378198</td>\n",
       "      <td>1.164633</td>\n",
       "      <td>1.335350</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.049808</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.063013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.073743</td>\n",
       "      <td>2.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>41.212247</td>\n",
       "      <td>35.870848</td>\n",
       "      <td>0.009651</td>\n",
       "      <td>0.159995</td>\n",
       "      <td>5.341399</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.742500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>41.630001</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>39.987500</td>\n",
       "      <td>39.242143</td>\n",
       "      <td>38.643929</td>\n",
       "      <td>1.485448</td>\n",
       "      <td>1.326377</td>\n",
       "      <td>1.484940</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.039455</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.057359</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.071729</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>41.613808</td>\n",
       "      <td>35.674049</td>\n",
       "      <td>0.000389</td>\n",
       "      <td>0.166955</td>\n",
       "      <td>5.939758</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.962502</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>42.812500</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>40.650000</td>\n",
       "      <td>39.621607</td>\n",
       "      <td>38.989881</td>\n",
       "      <td>1.573873</td>\n",
       "      <td>1.533400</td>\n",
       "      <td>1.571253</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.050511</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.074532</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.089287</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>42.132386</td>\n",
       "      <td>35.847376</td>\n",
       "      <td>0.016142</td>\n",
       "      <td>0.194299</td>\n",
       "      <td>6.285010</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.882500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>43.544998</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>41.236428</td>\n",
       "      <td>39.998571</td>\n",
       "      <td>39.298452</td>\n",
       "      <td>1.796852</td>\n",
       "      <td>1.800364</td>\n",
       "      <td>1.794729</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.053016</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.081443</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.097521</td>\n",
       "      <td>5.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>42.887911</td>\n",
       "      <td>35.708994</td>\n",
       "      <td>0.015321</td>\n",
       "      <td>0.219441</td>\n",
       "      <td>7.178918</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.630001</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>43.560001</td>\n",
       "      <td>AAPL</td>\n",
       "      <td>41.877143</td>\n",
       "      <td>40.343214</td>\n",
       "      <td>39.611667</td>\n",
       "      <td>1.694387</td>\n",
       "      <td>1.991546</td>\n",
       "      <td>1.938531</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.038633</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.073847</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-0.090641</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>43.488729</td>\n",
       "      <td>35.734604</td>\n",
       "      <td>0.001639</td>\n",
       "      <td>0.218987</td>\n",
       "      <td>7.754125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>43.125000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'continuous_feature_cutoff' : 0.6,\n",
    "              'stock_field' : 'ticker',\n",
    "              'calculation_field' : 'close',\n",
    "              'drop_original_fields' : True,\n",
    "              'drop_stock_field': True, # keep this fixed \n",
    "              'test_size' : 0.20,\n",
    "              'seed' : 1187,\n",
    "              'cross_val_splits' : 5,\n",
    "              'c' : 1.0,\n",
    "              'kernel' : 'rbf',\n",
    "              'gamma' : 'scale'\n",
    "              \n",
    "              }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test: standardize features:\n",
    "test = standardize_continuous_features(dataframe = df, parameters = parameters)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one-hot encode: \n",
    "test = one_hot_encode_tickers(dataframe = test, parameters= parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">20</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">21</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">22</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">23</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">24</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">25</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">27</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">28</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">29</span>    <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">1</span>\n",
       "Name: target_20_days_ahead_ind, dtype: int64\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;36m20\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m21\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m22\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m23\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m24\u001b[0m    \u001b[1;36m0\u001b[0m\n",
       "\u001b[1;36m25\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m26\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m27\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m28\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "\u001b[1;36m29\u001b[0m    \u001b[1;36m1\u001b[0m\n",
       "Name: target_20_days_ahead_ind, dtype: int64\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "test['target_20_days_ahead_ind'][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train-test splits:\n",
    "X_train, X_test, y_train, y_test = create_training_test_splits(dataframe=test, parameters= parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_20_days_ahead_ind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1761</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>262</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1168</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1547</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1251</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1644</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1428</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1073</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2121 rows Ã— 1 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### - Function development HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to profile the dataset target variable to determine whether we need to do some sort of rebalancing:\n",
    "\n",
    "def profile_target_variable(dataframe: pd.DataFrame, parameters: dict):\n",
    "\n",
    "\n",
    "    '''Function that looks at the target variable and creates an output for the user to review and decide whether rebalancing will help classification task\n",
    "    Args:\n",
    "        dataframe: Main resulting dataframe from all data conversion steps\n",
    "        parameters:\n",
    "            \n",
    "    \n",
    "    '''\n",
    "    # isolate the target variable:\n",
    "    target_field = list(dataframe.columns[dataframe.columns.str.contains('target')])\n",
    "\n",
    "    # create simple value count outputs:\n",
    "    target_summary_table = pd.DataFrame(dataframe[target_field].value_counts()).reset_index()\n",
    "    target_summary_table.rename(columns = {0 : 'counts'}, inplace = True)\n",
    "    target_summary_table['proportion'] = target_summary_table['counts'] / target_summary_table['counts'].sum()\n",
    "\n",
    "    # create bargraph and save it:\n",
    "    ''' TODO : resolve ability to output a matplotlib plot in kedro catalog\n",
    "    sns.countplot(x=target_field, data=dataframe)\n",
    "    plt.title(\"Class Distribution\")\n",
    "    plt.show() '''\n",
    "    target_field =', '.join(test.columns[test.columns.str.contains('target')].str.replace(r'\\[|\\]', ''))\n",
    "    positive_proportion = target_summary_table[target_summary_table[target_field].astype(int) == 1]['proportion'].to_list()\n",
    "   \n",
    "\n",
    "    print('Classification target: ' + str(target_field) + \" contains a class balance of: \" + str(positive_proportion) + \" in the positive case\")\n",
    "           \n",
    "\n",
    "    return target_summary_table # TODO: Write this to the catalouge as a reporting output for the users\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/07/24 10:29:06] </span><span style=\"color: #800000; text-decoration-color: #800000\">WARNING </span> <span style=\"color: #800080; text-decoration-color: #800080\">/opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/</span><span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">i</span> <a href=\"file:///opt/anaconda3/envs/stock-classification/lib/python3.7/warnings.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">warnings.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/stock-classification/lib/python3.7/warnings.py#110\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">110</span></a>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         <span style=\"color: #ff00ff; text-decoration-color: #ff00ff\">pykernel_launcher.py</span>:<span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">26</span>: FutureWarning: The default value of regex     <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>         will change from <span style=\"color: #00ff00; text-decoration-color: #00ff00; font-style: italic\">True</span> to <span style=\"color: #ff0000; text-decoration-color: #ff0000; font-style: italic\">False</span> in a future version.                    <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "<span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">                    </span>                                                                                <span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">               </span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/07/24 10:29:06]\u001b[0m\u001b[2;36m \u001b[0m\u001b[31mWARNING \u001b[0m \u001b[35m/opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/\u001b[0m\u001b[95mi\u001b[0m \u001b]8;id=148812;file:///opt/anaconda3/envs/stock-classification/lib/python3.7/warnings.py\u001b\\\u001b[2mwarnings.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=361863;file:///opt/anaconda3/envs/stock-classification/lib/python3.7/warnings.py#110\u001b\\\u001b[2m110\u001b[0m\u001b]8;;\u001b\\\n",
       "\u001b[2;36m                    \u001b[0m         \u001b[95mpykernel_launcher.py\u001b[0m:\u001b[1;36m26\u001b[0m: FutureWarning: The default value of regex     \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m         will change from \u001b[3;92mTrue\u001b[0m to \u001b[3;91mFalse\u001b[0m in a future version.                    \u001b[2m               \u001b[0m\n",
       "\u001b[2;36m                    \u001b[0m                                                                                \u001b[2m               \u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification target: target_20_days_ahead_ind contains a class balance of: [0.6210407239819005] in the positive case\n"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">[</span><span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.6210407239819005</span><span style=\"font-weight: bold\">]</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m[\u001b[0m\u001b[1;36m0.6210407239819005\u001b[0m\u001b[1m]\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>target_20_days_ahead_ind</th>\n",
       "      <th>counts</th>\n",
       "      <th>proportion</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1647</td>\n",
       "      <td>0.621041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>1005</td>\n",
       "      <td>0.378959</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############################ - Machine learning loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# classifiers to use: support vector machine, decision tree, random forest, xgboost, adaboost\n",
    "\n",
    "# TODO: Add in the confusion matrix values to make output analysis more straightforward\n",
    "\n",
    "def train_models(X_train: pd.DataFrame, y_train: pd.DataFrame, parameters) -> pd.DataFrame:\n",
    "\n",
    "    '''Trains a series of machine learning model outputs for evaluation by the user\n",
    "    \n",
    "    Args:\n",
    "        X_train: inputs from train-test split function\n",
    "        y_train: y-series from the train-test split function\n",
    "\n",
    "    Returns:\n",
    "        Summarized output of all ML models tried\n",
    "    \n",
    "    '''\n",
    "\n",
    "    # define all of the models to be used:\n",
    "    classifiers = {\n",
    "    \"LogisticRegression\": LogisticRegression(n_jobs = -1, max_iter = 100000),\n",
    "    \"RandomForestClassifier\": RandomForestClassifier(n_jobs = -1),\n",
    "    \"SVC\": SVC(C = parameters['c'], kernel =parameters['kernel'], gamma = parameters['gamma']),\n",
    "    \"AdaBoostClassifier\": AdaBoostClassifier()\n",
    "    }\n",
    "\n",
    "    # create a readable representation of the target:\n",
    "    y_train = y_train.iloc[:, 0].values\n",
    "    X_train = X_train.values\n",
    "\n",
    "    #TODO: add precision, recall, f-measure on all sets\n",
    "    #accuracies = {}\n",
    "    names = []\n",
    "    models = []\n",
    "    fold = []\n",
    "    training_samples = []\n",
    "\n",
    "    #TODO: Rename test to validation **\n",
    "\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    train_precisions = []\n",
    "    test_precisions = []\n",
    "\n",
    "    train_recalls = []\n",
    "    test_recalls = []\n",
    "\n",
    "    train_f_measures = []\n",
    "    test_f_measures = []\n",
    "\n",
    "    # iterate through the models:\n",
    "    for name, classifier in classifiers.items():\n",
    "\n",
    "        clf = classifier\n",
    "        print(name)\n",
    "        print (clf)\n",
    "\n",
    "        # iterate through the folds: ->> not ideal to nest the loops here\n",
    "        cv = StratifiedKFold(n_splits=parameters['cross_val_splits'], shuffle=True, random_state=parameters['seed']).split(X_train, y_train)\n",
    "\n",
    "        for k, (fold_train, fold_test) in enumerate(cv):\n",
    "\n",
    "             # append model name into list:\n",
    "            models.append(str(classifier))\n",
    "            \n",
    "            clf.fit(X_train[fold_train],y_train[fold_train])\n",
    "        \n",
    "\n",
    "            # create predictions:\n",
    "            train_pred = clf.predict(X = X_train[fold_train])\n",
    "            test_pred = clf.predict(X = X_train[fold_test])\n",
    "\n",
    "            # calculate accuracies:\n",
    "            train_accuracy = clf.score(X_train[fold_train], y_train[fold_train])\n",
    "            test_accuracy = clf.score(X_train[fold_test], y_train[fold_test])\n",
    "    \n",
    "            # calculate precision:\n",
    "            train_precision = precision_score(y_train[fold_train], train_pred)\n",
    "            test_precision = precision_score(y_train[fold_test], test_pred)\n",
    " \n",
    "            # calculate recall:\n",
    "            train_recall = recall_score(y_train[fold_train], train_pred)\n",
    "            test_recall = recall_score(y_train[fold_test], test_pred)\n",
    "\n",
    "            # calculate f-measure:\n",
    "            train_f = f1_score(y_train[fold_train], train_pred)\n",
    "            test_f = f1_score(y_train[fold_test], test_pred)\n",
    "            \n",
    "\n",
    "            # append name:\n",
    "            names.append(name)\n",
    "            \n",
    "            # append training sample size:\n",
    "            training_samples.append( len(X_train[fold_train]) )\n",
    "\n",
    "            # append fold number to the list:\n",
    "            fold.append(k+1)\n",
    "\n",
    "            # append score into list:\n",
    "            train_accuracies.append(train_accuracy)\n",
    "            test_accuracies.append(test_accuracy)\n",
    "\n",
    "            # append precisions to the list:\n",
    "            train_precisions.append(train_precision)\n",
    "            test_precisions.append(test_precision)\n",
    "\n",
    "            # append recalls to the list:\n",
    "            train_recalls.append(train_recall)\n",
    "            test_recalls.append(test_recall)\n",
    "\n",
    "            # append f-measures to the list:\n",
    "            train_f_measures.append(train_f)\n",
    "            test_f_measures.append(test_f)\n",
    "    \n",
    "    results_df = pd.DataFrame({\n",
    "                \"names\" : names,\n",
    "                \"model\" : models,\n",
    "                \"fold\" : fold,\n",
    "                \"training_samples\" : training_samples,\n",
    "                \"train_accuracy\": train_accuracies,\n",
    "                \"test_accuracy\": test_accuracies,\n",
    "                \"train_precision\": train_precisions,\n",
    "                \"test_precision\": test_precisions,\n",
    "                \"train_recall\": train_recalls,\n",
    "                \"test_recall\": test_recalls,\n",
    "                \"train_f_measures\": train_f_measures,\n",
    "                \"test_f_measures\": test_f_measures\n",
    "                \n",
    "                })\n",
    "\n",
    "    # create aggregated results df:\n",
    "    aggregated_results_df = results_df.drop(columns = ['fold']).groupby(by = ['names', 'model']).mean()\n",
    "                            \n",
    "    \n",
    "    return results_df, aggregated_results_df #names, model, fold, train_accuracies, test_accuracies, train_precisions, test_precisions\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### - Testing functions HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LogisticRegression\n",
      "LogisticRegression(max_iter=100000, n_jobs=-1)\n",
      "RandomForestClassifier\n",
      "RandomForestClassifier(n_jobs=-1)\n",
      "SVC\n",
      "SVC()\n",
      "AdaBoostClassifier\n",
      "AdaBoostClassifier()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#names, model, fold, train_accuracies, test_accuracies, train_precisions, test_precisions \n",
    "\n",
    "output, aggregated_output= train_models(X_train = X_train, y_train = y_train, parameters = parameters)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>model</th>\n",
       "      <th>fold</th>\n",
       "      <th>training_samples</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f_measures</th>\n",
       "      <th>test_f_measures</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(max_iter=100000, n_jobs=-1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1696</td>\n",
       "      <td>0.635024</td>\n",
       "      <td>0.647059</td>\n",
       "      <td>0.655222</td>\n",
       "      <td>0.654891</td>\n",
       "      <td>0.869896</td>\n",
       "      <td>0.912879</td>\n",
       "      <td>0.747450</td>\n",
       "      <td>0.762658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(max_iter=100000, n_jobs=-1)</td>\n",
       "      <td>2</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.654095</td>\n",
       "      <td>0.639151</td>\n",
       "      <td>0.668353</td>\n",
       "      <td>0.659942</td>\n",
       "      <td>0.878443</td>\n",
       "      <td>0.867424</td>\n",
       "      <td>0.759130</td>\n",
       "      <td>0.749591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(max_iter=100000, n_jobs=-1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.643489</td>\n",
       "      <td>0.608491</td>\n",
       "      <td>0.661163</td>\n",
       "      <td>0.641399</td>\n",
       "      <td>0.873814</td>\n",
       "      <td>0.836502</td>\n",
       "      <td>0.752758</td>\n",
       "      <td>0.726073</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(max_iter=100000, n_jobs=-1)</td>\n",
       "      <td>4</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.636417</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.651002</td>\n",
       "      <td>0.641096</td>\n",
       "      <td>0.893738</td>\n",
       "      <td>0.889734</td>\n",
       "      <td>0.753299</td>\n",
       "      <td>0.745223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LogisticRegression</td>\n",
       "      <td>LogisticRegression(max_iter=100000, n_jobs=-1)</td>\n",
       "      <td>5</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.641131</td>\n",
       "      <td>0.653302</td>\n",
       "      <td>0.655052</td>\n",
       "      <td>0.662921</td>\n",
       "      <td>0.891841</td>\n",
       "      <td>0.897338</td>\n",
       "      <td>0.755323</td>\n",
       "      <td>0.762520</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1)</td>\n",
       "      <td>1</td>\n",
       "      <td>1696</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.858824</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.854167</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931818</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1)</td>\n",
       "      <td>2</td>\n",
       "      <td>1697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.863208</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.857639</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.935606</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.894928</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1)</td>\n",
       "      <td>3</td>\n",
       "      <td>1697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.860849</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.861702</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.923954</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.891743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1)</td>\n",
       "      <td>4</td>\n",
       "      <td>1697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.849057</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.856631</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.908745</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.881919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>RandomForestClassifier</td>\n",
       "      <td>RandomForestClassifier(n_jobs=-1)</td>\n",
       "      <td>5</td>\n",
       "      <td>1697</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.903302</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.914179</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.931559</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.922787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>1</td>\n",
       "      <td>1696</td>\n",
       "      <td>0.648585</td>\n",
       "      <td>0.642353</td>\n",
       "      <td>0.645820</td>\n",
       "      <td>0.640000</td>\n",
       "      <td>0.961064</td>\n",
       "      <td>0.969697</td>\n",
       "      <td>0.772519</td>\n",
       "      <td>0.771084</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>2</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.631114</td>\n",
       "      <td>0.627358</td>\n",
       "      <td>0.628537</td>\n",
       "      <td>0.627404</td>\n",
       "      <td>0.991453</td>\n",
       "      <td>0.988636</td>\n",
       "      <td>0.769344</td>\n",
       "      <td>0.767647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>3</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.638774</td>\n",
       "      <td>0.636792</td>\n",
       "      <td>0.634862</td>\n",
       "      <td>0.631961</td>\n",
       "      <td>0.984820</td>\n",
       "      <td>0.992395</td>\n",
       "      <td>0.772034</td>\n",
       "      <td>0.772189</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>4</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.633471</td>\n",
       "      <td>0.627358</td>\n",
       "      <td>0.630593</td>\n",
       "      <td>0.626506</td>\n",
       "      <td>0.989564</td>\n",
       "      <td>0.988593</td>\n",
       "      <td>0.770310</td>\n",
       "      <td>0.766962</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>SVC</td>\n",
       "      <td>SVC()</td>\n",
       "      <td>5</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.644667</td>\n",
       "      <td>0.622642</td>\n",
       "      <td>0.640498</td>\n",
       "      <td>0.631714</td>\n",
       "      <td>0.975332</td>\n",
       "      <td>0.939163</td>\n",
       "      <td>0.773223</td>\n",
       "      <td>0.755352</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>1</td>\n",
       "      <td>1696</td>\n",
       "      <td>0.754127</td>\n",
       "      <td>0.708235</td>\n",
       "      <td>0.746130</td>\n",
       "      <td>0.707101</td>\n",
       "      <td>0.915480</td>\n",
       "      <td>0.905303</td>\n",
       "      <td>0.822175</td>\n",
       "      <td>0.794020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>2</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.764879</td>\n",
       "      <td>0.716981</td>\n",
       "      <td>0.759936</td>\n",
       "      <td>0.722222</td>\n",
       "      <td>0.907882</td>\n",
       "      <td>0.886364</td>\n",
       "      <td>0.827347</td>\n",
       "      <td>0.795918</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>3</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.746612</td>\n",
       "      <td>0.686321</td>\n",
       "      <td>0.754486</td>\n",
       "      <td>0.721088</td>\n",
       "      <td>0.877609</td>\n",
       "      <td>0.806084</td>\n",
       "      <td>0.811404</td>\n",
       "      <td>0.761221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>4</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.740719</td>\n",
       "      <td>0.698113</td>\n",
       "      <td>0.740219</td>\n",
       "      <td>0.705167</td>\n",
       "      <td>0.897533</td>\n",
       "      <td>0.882129</td>\n",
       "      <td>0.811321</td>\n",
       "      <td>0.783784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>AdaBoostClassifier</td>\n",
       "      <td>AdaBoostClassifier()</td>\n",
       "      <td>5</td>\n",
       "      <td>1697</td>\n",
       "      <td>0.757219</td>\n",
       "      <td>0.705189</td>\n",
       "      <td>0.749224</td>\n",
       "      <td>0.712963</td>\n",
       "      <td>0.915560</td>\n",
       "      <td>0.878327</td>\n",
       "      <td>0.824082</td>\n",
       "      <td>0.787053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>training_samples</th>\n",
       "      <th>train_accuracy</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>train_precision</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>train_recall</th>\n",
       "      <th>test_recall</th>\n",
       "      <th>train_f_measures</th>\n",
       "      <th>test_f_measures</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>names</th>\n",
       "      <th>model</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>AdaBoostClassifier</th>\n",
       "      <th>AdaBoostClassifier()</th>\n",
       "      <td>1696.8</td>\n",
       "      <td>0.752711</td>\n",
       "      <td>0.702968</td>\n",
       "      <td>0.749999</td>\n",
       "      <td>0.713708</td>\n",
       "      <td>0.902813</td>\n",
       "      <td>0.871641</td>\n",
       "      <td>0.819266</td>\n",
       "      <td>0.784399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <th>LogisticRegression(max_iter=100000, n_jobs=-1)</th>\n",
       "      <td>1696.8</td>\n",
       "      <td>0.642031</td>\n",
       "      <td>0.634129</td>\n",
       "      <td>0.658158</td>\n",
       "      <td>0.652050</td>\n",
       "      <td>0.881546</td>\n",
       "      <td>0.880775</td>\n",
       "      <td>0.753592</td>\n",
       "      <td>0.749213</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <th>RandomForestClassifier(n_jobs=-1)</th>\n",
       "      <td>1696.8</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.865162</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.866935</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.925576</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.895081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SVC</th>\n",
       "      <th>SVC()</th>\n",
       "      <td>1696.8</td>\n",
       "      <td>0.639322</td>\n",
       "      <td>0.631301</td>\n",
       "      <td>0.636062</td>\n",
       "      <td>0.631517</td>\n",
       "      <td>0.980446</td>\n",
       "      <td>0.975697</td>\n",
       "      <td>0.771486</td>\n",
       "      <td>0.766647</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aggregated_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier = logistic_regression(X = X_train, y = y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Next to-dos:  \n",
    "1.) Add parameters for all Classifiers to the parameters model  \n",
    "2.) Add Select \"n\" best logic to the outputs\n",
    "3.) Add in feature importances and feature selection before modeling run\n",
    "3.) Add in Hypterparameter tuning\n",
    "4.) Run with more positions/equity holdings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10939df48fcda05c4bec3e401945f701fe0f8ffca207b5e1a18717f88993ca17"
  },
  "kernelspec": {
   "display_name": "Kedro (stock_price_classification)",
   "language": "python",
   "name": "kedro_stock_price_classification"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
