{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "pd.set_option('display.max_columns', 100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# notebook goal: Setup a basic machine learning framework that cleans data, standardizes features,\n",
    "#  evaluates feature impt, shap values, and a myriad of ML algorithms\n",
    "# TODO: add the day-of-week as a feature\n",
    "# TODO: Add in target date versus historic reference dates\n",
    "# TODO: Add in volume-based feature functionality\n",
    "# TODO: Evaluate standardizing features per stock or one model per stock - may not be enough data realistically\n",
    "# TODO: Check bol-range-pct calculation - only giving zero value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [],
   "source": [
    "# functions:\n",
    "\n",
    "def clean_stock_data(dataframe: pd.DataFrame) -> pd.DataFrame :\n",
    "\n",
    "    '''removes nulls and in the future will be built out to do any additonal cleaning on the dataframe that is necessary\n",
    "    Args:\n",
    "        dataframe: pandas dataframe containing all of the potential features\n",
    "        parameters: \n",
    "            calculation_field: field on which all of the features are built\n",
    "\n",
    "    Returns:\n",
    "        dataframe: dataset that is ready to load into a machine learning framework\n",
    "    '''\n",
    "\n",
    "    # remove records the preceed the target period to have complete information:\n",
    "    dataframe.dropna(inplace = True)\n",
    "    dataframe = dataframe.reset_index(drop = True)\n",
    "    \n",
    "    # remove fields that will not be used as predictive features (can be hardcoded since dataframe structure will be the same):\n",
    "    dataframe = dataframe.drop(columns = [ 'date', 'ticker', 'high', 'low', 'open', 'volume', 'adj_close'])\n",
    "    \n",
    "\n",
    "    return dataframe\n",
    "\n",
    "\n",
    "def identify_fields_to_standardize(dataframe: pd.DataFrame, parameters: dict) -> np.array :\n",
    "\n",
    "    '''creates a list of the continuous fields to standardize by dimension within the predictive model; NOTE: this is used within the standardizer\n",
    "    \n",
    "    Args:\n",
    "        dataframe: dataframe that contains all of the fields of interest to be used in the calculations\n",
    "        parameters:\n",
    "            continuous_feature_cutoff: ratio of unique values to record count to be used to codify continuous features\n",
    "\n",
    "    Returns: list of continuous fields to use in the standardization process based on user's specifications of \"uniqueness\" threshold    \n",
    "\n",
    "    '''\n",
    "\n",
    "    numeric_fields = dataframe.select_dtypes(include = 'number').columns\n",
    "    records = len(dataframe)\n",
    "\n",
    "    record_summary = pd.DataFrame(dataframe[numeric_fields].nunique(), columns = ['unique_values'])\n",
    "    record_summary['rows_in_df'] = records\n",
    "    record_summary['value_to_record_ratio'] = record_summary['unique_values']/ record_summary['rows_in_df']\n",
    "\n",
    "    # filter for a threshold specified by the user:\n",
    "    record_summary = record_summary[record_summary['value_to_record_ratio'] > parameters['continuous_feature_cutoff']]\n",
    "\n",
    "    # remove percentage features # TODO: later add in functionality to remove percentage based features\n",
    "\n",
    "    return record_summary.index\n",
    "\n",
    "\n",
    "# Justification for approach on scaling - the argument can be made that since our approach will generalize movemements across multiple securities that we need to standardize each security to its own price range.  Therefore, any features with price-relative values will be scaled per the security's price values to avoid odd splits in tree-based algos\n",
    "# the concern with standardization is generally focused on not letting any one feature have considerably more weight in a model than another; however in this case, \n",
    "\n",
    "\n",
    "def standardize_continuous_features(dataframe: pd.DataFrame, parameters: dict) -> pd.DataFrame:\n",
    "\n",
    "    '''function that identifies the continuious features in the dataframe and standardizes each feature by equity to enable scaling relative to each equity\n",
    "    \n",
    "    Args:\n",
    "        Dataframe: Pandas dataframe to be used in machine learning\n",
    "        Parameters:\n",
    "            stock_field: field indicating the stock for the window function to scan\n",
    "            calculation_field: field for which the target is being calculated (used for drop in main row merge)\n",
    "    \n",
    "    Returns:\n",
    "        Dataframe: containing the standardized data fields\n",
    "    \n",
    "    '''\n",
    "\n",
    "    continuous_fields = list(identify_fields_to_standardize(dataframe = dataframe, parameters = parameters))\n",
    "\n",
    "    # add in the ticker for grouping next:\n",
    "    continuous_fields.append(parameters['stock_field'])\n",
    "\n",
    "    # downselect to the fields that will be used to standardize:\n",
    "    continuous_dataframe = dataframe[continuous_fields]\n",
    "\n",
    "    # calculate z-scores:\n",
    "    z_scores = (continuous_dataframe - continuous_dataframe.groupby(by = parameters['stock_field']).transform('mean')) / continuous_dataframe.groupby(by = parameters['stock_field']).transform('std')\n",
    "\n",
    "    # drop the null ticker (not needed post groupby): \n",
    "    z_scores.drop(columns = [ parameters['stock_field'], parameters['calculation_field'] ], inplace = True)\n",
    "\n",
    "    # rename the fields to indicate standardization:\n",
    "    z_scores.columns = z_scores.columns + '_std'\n",
    "\n",
    "    # drop original continuous fields # TODO: coming back after calculation checks:\n",
    "    if parameters['drop_original_fields'] == True:\n",
    "        continuous_fields.remove(parameters['stock_field'])\n",
    "        dataframe.drop(columns = continuous_fields, inplace = True)\n",
    "\n",
    "    # append the fields back into the core dataframe:\n",
    "    z_scores = pd.concat([dataframe, z_scores], axis = 1)\n",
    "\n",
    "    # remove the standardized target field:\n",
    "    z_scores.drop(columns = z_scores.columns[z_scores.columns.str.contains('target')][1], inplace = True)\n",
    "\n",
    "    # remove unnecessary items:\n",
    "    del continuous_fields, continuous_dataframe\n",
    "\n",
    "    return z_scores\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #7fbfbf; text-decoration-color: #7fbfbf\">[01/04/23 08:53:54] </span><span style=\"color: #000080; text-decoration-color: #000080\">INFO    </span> Loading data from <span style=\"color: #008000; text-decoration-color: #008000\">'combined_modeling_input'</span> <span style=\"font-weight: bold\">(</span>CSVDataSet<span style=\"font-weight: bold\">)</span><span style=\"color: #808000; text-decoration-color: #808000\">...</span>        <a href=\"file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">data_catalog.py</span></a><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">:</span><a href=\"file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py#344\" target=\"_blank\"><span style=\"color: #7f7f7f; text-decoration-color: #7f7f7f\">344</span></a>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[2;36m[01/04/23 08:53:54]\u001b[0m\u001b[2;36m \u001b[0m\u001b[34mINFO    \u001b[0m Loading data from \u001b[32m'combined_modeling_input'\u001b[0m \u001b[1m(\u001b[0mCSVDataSet\u001b[1m)\u001b[0m\u001b[33m...\u001b[0m        \u001b]8;id=913467;file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py\u001b\\\u001b[2mdata_catalog.py\u001b[0m\u001b]8;;\u001b\\\u001b[2m:\u001b[0m\u001b]8;id=55869;file:///opt/anaconda3/envs/stock-classification/lib/python3.7/site-packages/kedro/io/data_catalog.py#344\u001b\\\u001b[2m344\u001b[0m\u001b]8;;\u001b\\\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = catalog.load('combined_modeling_input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameters = {'continuous_feature_cutoff' : 0.60,\n",
    "              'stock_field' : 'ticker',\n",
    "              'calculation_field' : 'close',\n",
    "              'drop_original_fields' : True}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### - Function development HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_training_test_splits(dataframe: pd.DataFrame, parameters: dict) -> pd.DataFrame:\n",
    "\n",
    "    '''Function that splits out training and test sets for machine learning\n",
    "    Args:\n",
    "        dataframe: pandas dataframe containing only the target field and the features to be used by the classifier\n",
    "        parameters:\n",
    "            test_ratio: proportion of samples in the dataframe to be used as a test set once the models are tuned and evaluated\n",
    "\n",
    "    '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "##################################### - Testing functions HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test run code chunk:\n",
    "\n",
    "df = clean_stock_data(dataframe= df)\n",
    "\n",
    "# create the standardized features:\n",
    "\n",
    "df = standardize_continuous_features(dataframe = df, parameters = parameters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #008000; text-decoration-color: #008000\">'target_20_days_ahead_ind'</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[32m'target_20_days_ahead_ind'\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# drop the standardized target field:\n",
    "#df.columns[df.columns.str.contains('target')][0]\n",
    "\n",
    "# separated out the target field:\n",
    "df.columns[df.columns.str.contains('target')][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">\n",
       "<span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">Index</span><span style=\"font-weight: bold\">([</span><span style=\"color: #008000; text-decoration-color: #008000\">'date'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'ticker'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'above_7_close_sma_ind'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'above_14_close_sma_ind'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'above_21_close_sma_ind'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'cum_days_above_above_7_close_sma_ind'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'cum_days_above_above_14_close_sma_ind'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'cum_days_above_above_21_close_sma_ind'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'bol_range_pct'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'target_20_days_ahead_ind'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'14_close_sma_std'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'14_close_sma_pct_diff_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'14_close_std_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'21_close_sma_std'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'21_close_sma_pct_diff_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'21_close_std_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'7_close_sma_std'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'7_close_sma_pct_diff_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'7_close_std_std'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'bol_pct_from_bottom_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'bol_pct_from_top_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'bol_range_std'</span>,\n",
       "       <span style=\"color: #008000; text-decoration-color: #008000\">'lower_bollinger_band_std'</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'upper_bollinger_band_std'</span><span style=\"font-weight: bold\">]</span>,\n",
       "      <span style=\"color: #808000; text-decoration-color: #808000\">dtype</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'object'</span><span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\n",
       "\u001b[1;35mIndex\u001b[0m\u001b[1m(\u001b[0m\u001b[1m[\u001b[0m\u001b[32m'date'\u001b[0m, \u001b[32m'ticker'\u001b[0m, \u001b[32m'above_7_close_sma_ind'\u001b[0m, \u001b[32m'above_14_close_sma_ind'\u001b[0m,\n",
       "       \u001b[32m'above_21_close_sma_ind'\u001b[0m, \u001b[32m'cum_days_above_above_7_close_sma_ind'\u001b[0m,\n",
       "       \u001b[32m'cum_days_above_above_14_close_sma_ind'\u001b[0m,\n",
       "       \u001b[32m'cum_days_above_above_21_close_sma_ind'\u001b[0m, \u001b[32m'bol_range_pct'\u001b[0m,\n",
       "       \u001b[32m'target_20_days_ahead_ind'\u001b[0m, \u001b[32m'14_close_sma_std'\u001b[0m,\n",
       "       \u001b[32m'14_close_sma_pct_diff_std'\u001b[0m, \u001b[32m'14_close_std_std'\u001b[0m, \u001b[32m'21_close_sma_std'\u001b[0m,\n",
       "       \u001b[32m'21_close_sma_pct_diff_std'\u001b[0m, \u001b[32m'21_close_std_std'\u001b[0m, \u001b[32m'7_close_sma_std'\u001b[0m,\n",
       "       \u001b[32m'7_close_sma_pct_diff_std'\u001b[0m, \u001b[32m'7_close_std_std'\u001b[0m,\n",
       "       \u001b[32m'bol_pct_from_bottom_std'\u001b[0m, \u001b[32m'bol_pct_from_top_std'\u001b[0m, \u001b[32m'bol_range_std'\u001b[0m,\n",
       "       \u001b[32m'lower_bollinger_band_std'\u001b[0m, \u001b[32m'upper_bollinger_band_std'\u001b[0m\u001b[1m]\u001b[0m,\n",
       "      \u001b[33mdtype\u001b[0m=\u001b[32m'object'\u001b[0m\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "10939df48fcda05c4bec3e401945f701fe0f8ffca207b5e1a18717f88993ca17"
  },
  "kernelspec": {
   "display_name": "Kedro (stock_price_classification)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
